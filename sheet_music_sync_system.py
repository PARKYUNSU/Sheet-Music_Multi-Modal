"""
ì•…ë³´-ì—°ì£¼ ì‹±í¬ ì‹œìŠ¤í…œ
OMR ê²°ê³¼ì™€ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ë¥¼ ë™ê¸°í™”í•˜ì—¬ í˜„ì¬ ì—°ì£¼ ìœ„ì¹˜ë¥¼ ì¶”ì 
"""

import json
import numpy as np
import time
import threading
from typing import List, Dict, Optional, Tuple
from collections import deque
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import librosa
from improved_omr import ImprovedOMR
from real_time_audio_processor import RealTimeAudioProcessor

class SheetMusicSyncSystem:
    def __init__(self, sheet_music_path: str, audio_file_path: str):
        """
        ì•…ë³´-ì—°ì£¼ ì‹±í¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            sheet_music_path: ì•…ë³´ ì´ë¯¸ì§€ ê²½ë¡œ
            audio_file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        self.sheet_music_path = sheet_music_path
        self.audio_file_path = audio_file_path
        
        # OMR ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("ğŸ¼ OMR ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        self.omr = ImprovedOMR()
        self.sheet_music_data = None
        
        # ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("ğŸµ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        self.audio_processor = RealTimeAudioProcessor(audio_file_path)
        
        # ë™ê¸°í™” ìƒíƒœ
        self.sync_state = {
            'current_position': 0,  # í˜„ì¬ ì—°ì£¼ ìœ„ì¹˜ (ìŒí‘œ ì¸ë±ìŠ¤)
            'sync_confidence': 0.0,  # ë™ê¸°í™” ì‹ ë¢°ë„ (0-1)
            'is_synced': False,  # ë™ê¸°í™” ìƒíƒœ
            'tempo': 120.0,  # í˜„ì¬ í…œí¬ (BPM)
            'last_sync_time': 0,  # ë§ˆì§€ë§‰ ë™ê¸°í™” ì‹œê°„
            'sync_history': deque(maxlen=50)  # ë™ê¸°í™” íˆìŠ¤í† ë¦¬
        }
        
        # ë§¤ì¹­ ì„¤ì •
        self.pitch_tolerance = 50  # ìŒë†’ì´ í—ˆìš© ì˜¤ì°¨ (ì„¼íŠ¸)
        self.tempo_tolerance = 0.2  # í…œí¬ í—ˆìš© ì˜¤ì°¨ (20%)
        self.sync_threshold = 0.7  # ë™ê¸°í™” ìµœì†Œ ì‹ ë¢°ë„
        
        print("âœ… ì•…ë³´-ì—°ì£¼ ì‹±í¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_sheet_music(self):
        """ì•…ë³´ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ğŸ“„ ì•…ë³´ ë°ì´í„° ë¡œë”©...")
        
        # OMRë¡œ ì•…ë³´ ë¶„ì„
        self.sheet_music_data = self.omr.process_sheet_music_improved(self.sheet_music_path)
        
        # ìŒí‘œ ë°ì´í„°ë¥¼ ì‹œê°„ì¶•ìœ¼ë¡œ ë³€í™˜
        self.convert_notes_to_timeline()
        
        print(f"âœ… ì•…ë³´ ë¡œë“œ ì™„ë£Œ: {len(self.sheet_music_data['notes'])}ê°œ ìŒí‘œ")
    
    def convert_notes_to_timeline(self):
        """ìŒí‘œ ë°ì´í„°ë¥¼ ì‹œê°„ì¶•ìœ¼ë¡œ ë³€í™˜"""
        if not self.sheet_music_data or 'notes' not in self.sheet_music_data:
            return
        
        notes = self.sheet_music_data['notes']
        tempo = self.sync_state['tempo']
        
        # ê° ìŒí‘œì— ì‹œê°„ ì •ë³´ ì¶”ê°€
        current_time = 0.0
        for i, note in enumerate(notes):
            # ìŒí‘œ ì‹œì‘ ì‹œê°„
            note['start_time'] = current_time
            
            # ìŒí‘œ ê¸¸ì´ ê³„ì‚° (durationì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜)
            note_duration = note.get('duration', 1.0)  # ê¸°ë³¸ 1ë°•ì
            note['end_time'] = current_time + (note_duration * 60.0 / tempo)
            
            # ë‹¤ìŒ ìŒí‘œ ì‹œì‘ ì‹œê°„
            current_time = note['end_time']
            
            # ìŒí‘œ ì¸ë±ìŠ¤ ì¶”ê°€
            note['index'] = i
        
        print(f"âœ… ì‹œê°„ì¶• ë³€í™˜ ì™„ë£Œ: ì´ {current_time:.2f}ì´ˆ")
    
    def frequency_to_cents(self, freq1: float, freq2: float) -> float:
        """ë‘ ì£¼íŒŒìˆ˜ ê°„ì˜ ì„¼íŠ¸ ì°¨ì´ ê³„ì‚°"""
        if freq1 <= 0 or freq2 <= 0:
            return float('inf')
        return 1200 * np.log2(freq2 / freq1)
    
    def note_name_to_frequency(self, note_name: str) -> float:
        """ìŒí‘œëª…ì„ ì£¼íŒŒìˆ˜ë¡œ ë³€í™˜"""
        if note_name == "Silence":
            return 0.0
        
        # A4 = 440Hz ê¸°ì¤€
        note_map = {
            'C': -9, 'C#': -8, 'D': -7, 'D#': -6, 'E': -5, 'F': -4,
            'F#': -3, 'G': -2, 'G#': -1, 'A': 0, 'A#': 1, 'B': 2
        }
        
        try:
            note = note_name[:-1]  # ìŒí‘œëª… (C, D, E ë“±)
            octave = int(note_name[-1])  # ì˜¥íƒ€ë¸Œ (4, 5 ë“±)
            
            semitones = note_map[note] + (octave - 4) * 12
            frequency = 440.0 * (2 ** (semitones / 12))
            return frequency
        except:
            return 0.0
    
    def match_pitch(self, current_pitch: float, note_frequency: float) -> float:
        """ìŒë†’ì´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        if current_pitch <= 0 or note_frequency <= 0:
            return 0.0
        
        cents_diff = abs(self.frequency_to_cents(current_pitch, note_frequency))
        
        # í—ˆìš© ì˜¤ì°¨ ë‚´ì— ìˆìœ¼ë©´ ë†’ì€ ì ìˆ˜
        if cents_diff <= self.pitch_tolerance:
            return 1.0 - (cents_diff / self.pitch_tolerance)
        else:
            return 0.0
    
    def find_best_match(self, current_pitch: float, current_time: float) -> Tuple[Optional[Dict], float]:
        """í˜„ì¬ ì—°ì£¼ì™€ ê°€ì¥ ì˜ ë§ëŠ” ì•…ë³´ ìœ„ì¹˜ ì°¾ê¸°"""
        if not self.sheet_music_data or 'notes' not in self.sheet_music_data:
            return None, 0.0
        
        notes = self.sheet_music_data['notes']
        best_match = None
        best_score = 0.0
        
        # í˜„ì¬ ì‹œê°„ ì£¼ë³€ì˜ ìŒí‘œë“¤ì„ ê²€ì‚¬
        time_window = 5.0  # 5ì´ˆ ìœˆë„ìš°
        
        for note in notes:
            note_freq = self.note_name_to_frequency(note['pitch'])
            
            # ì‹œê°„ ë§¤ì¹­ ì ìˆ˜
            time_diff = abs(current_time - note['start_time'])
            if time_diff > time_window:
                continue
            
            time_score = 1.0 - (time_diff / time_window)
            
            # ìŒë†’ì´ ë§¤ì¹­ ì ìˆ˜
            pitch_score = self.match_pitch(current_pitch, note_freq)
            
            # ì¢…í•© ì ìˆ˜ (ì‹œê°„ 60%, ìŒë†’ì´ 40%)
            total_score = 0.6 * time_score + 0.4 * pitch_score
            
            if total_score > best_score:
                best_score = total_score
                best_match = note
        
        return best_match, best_score
    
    def update_sync_state(self, current_pitch: float, current_time: float):
        """ë™ê¸°í™” ìƒíƒœ ì—…ë°ì´íŠ¸"""
        # ìµœì  ë§¤ì¹­ ì°¾ê¸°
        best_match, match_score = self.find_best_match(current_pitch, current_time)
        
        if best_match and match_score >= self.sync_threshold:
            # ë™ê¸°í™” ì„±ê³µ
            self.sync_state['current_position'] = best_match['index']
            self.sync_state['sync_confidence'] = match_score
            self.sync_state['is_synced'] = True
            self.sync_state['last_sync_time'] = current_time
            
            # ë™ê¸°í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.sync_state['sync_history'].append({
                'time': current_time,
                'position': best_match['index'],
                'confidence': match_score,
                'pitch': current_pitch,
                'note': best_match['pitch']
            })
        else:
            # ë™ê¸°í™” ì‹¤íŒ¨
            self.sync_state['sync_confidence'] = match_score
            self.sync_state['is_synced'] = False
    
    def get_current_note_info(self) -> Dict:
        """í˜„ì¬ ì—°ì£¼ ì¤‘ì¸ ìŒí‘œ ì •ë³´ ë°˜í™˜"""
        if not self.sync_state['is_synced']:
            return {
                'note': None,
                'position': -1,
                'confidence': 0.0,
                'status': 'not_synced'
            }
        
        notes = self.sheet_music_data['notes']
        current_pos = self.sync_state['current_position']
        
        if 0 <= current_pos < len(notes):
            current_note = notes[current_pos]
            return {
                'note': current_note,
                'position': current_pos,
                'confidence': self.sync_state['sync_confidence'],
                'status': 'synced',
                'next_notes': notes[current_pos:current_pos+3]  # ë‹¤ìŒ 3ê°œ ìŒí‘œ
            }
        else:
            return {
                'note': None,
                'position': -1,
                'confidence': 0.0,
                'status': 'out_of_range'
            }
    
    def start_sync_monitoring(self, duration: float = 30.0):
        """ë™ê¸°í™” ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        print(f"ğŸ”„ ë™ê¸°í™” ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ìµœëŒ€ {duration}ì´ˆ)...")
        
        # ì•…ë³´ ë°ì´í„° ë¡œë“œ
        self.load_sheet_music()
        
        # ì˜¤ë””ì˜¤ ë¶„ì„
        print("ğŸ” ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘...")
        audio_analysis = self.audio_processor.analyze_full_audio()
        
        # ì‹¤ì‹œê°„ ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜
        results = audio_analysis['detailed_results']
        sync_results = []
        
        for result in results[:int(duration * 10)]:  # 0.1ì´ˆ ë‹¨ìœ„ë¡œ ì œí•œ
            current_time = result['time']
            current_pitch = result['pitch']
            
            # ë™ê¸°í™” ìƒíƒœ ì—…ë°ì´íŠ¸
            self.update_sync_state(current_pitch, current_time)
            
            # ê²°ê³¼ ì €ì¥
            sync_info = self.get_current_note_info()
            sync_results.append({
                'time': current_time,
                'audio_pitch': current_pitch,
                'sync_info': sync_info,
                'sync_state': self.sync_state.copy()
            })
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if len(sync_results) % 50 == 0:  # 5ì´ˆë§ˆë‹¤ ì¶œë ¥
                print(f"â±ï¸ {current_time:.1f}ì´ˆ: "
                      f"ìŒë†’ì´={current_pitch:.1f}Hz, "
                      f"ìœ„ì¹˜={sync_info['position']}, "
                      f"ì‹ ë¢°ë„={sync_info['confidence']:.2f}")
        
        return sync_results
    
    def visualize_sync_results(self, sync_results: List[Dict]):
        """ë™ê¸°í™” ê²°ê³¼ ì‹œê°í™”"""
        print("ğŸ“Š ë™ê¸°í™” ê²°ê³¼ ì‹œê°í™”...")
        
        times = [r['time'] for r in sync_results]
        audio_pitches = [r['audio_pitch'] for r in sync_results]
        sync_positions = [r['sync_info']['position'] for r in sync_results]
        sync_confidences = [r['sync_info']['confidence'] for r in sync_results]
        
        # ê·¸ë˜í”„ ìƒì„±
        fig, axes = plt.subplots(3, 1, figsize=(15, 12))
        
        # 1. ì˜¤ë””ì˜¤ ìŒë†’ì´ vs ì•…ë³´ ìŒë†’ì´
        axes[0].plot(times, audio_pitches, 'b-', alpha=0.7, label='Audio Pitch')
        
        # ì•…ë³´ ìŒë†’ì´ í‘œì‹œ
        if self.sheet_music_data and 'notes' in self.sheet_music_data:
            notes = self.sheet_music_data['notes']
            note_times = [note['start_time'] for note in notes]
            note_freqs = [self.note_name_to_frequency(note['pitch']) for note in notes]
            axes[0].scatter(note_times, note_freqs, c='red', s=50, alpha=0.8, label='Sheet Music')
        
        axes[0].set_title('Audio Pitch vs Sheet Music')
        axes[0].set_ylabel('Frequency (Hz)')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # 2. ë™ê¸°í™” ìœ„ì¹˜
        axes[1].plot(times, sync_positions, 'g-', alpha=0.7)
        axes[1].set_title('Sync Position')
        axes[1].set_ylabel('Note Index')
        axes[1].grid(True, alpha=0.3)
        
        # 3. ë™ê¸°í™” ì‹ ë¢°ë„
        axes[2].plot(times, sync_confidences, 'r-', alpha=0.7)
        axes[2].axhline(y=self.sync_threshold, color='orange', linestyle='--', label='Sync Threshold')
        axes[2].set_title('Sync Confidence')
        axes[2].set_ylabel('Confidence')
        axes[2].set_xlabel('Time (seconds)')
        axes[2].legend()
        axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('sync_analysis_result.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("âœ… ì‹œê°í™” ì™„ë£Œ: sync_analysis_result.png")
    
    def save_sync_results(self, sync_results: List[Dict], filename: str = 'sync_results.json'):
        """ë™ê¸°í™” ê²°ê³¼ ì €ì¥"""
        def convert_numpy_types(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, deque):
                return list(obj)  # dequeë¥¼ listë¡œ ë³€í™˜
            elif isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            return obj
        
        serializable_results = convert_numpy_types(sync_results)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ë™ê¸°í™” ê²°ê³¼ ì €ì¥: {filename}")
    
    def get_sync_statistics(self, sync_results: List[Dict]) -> Dict:
        """ë™ê¸°í™” í†µê³„ ê³„ì‚°"""
        total_samples = len(sync_results)
        synced_samples = sum(1 for r in sync_results if r['sync_info']['status'] == 'synced')
        
        avg_confidence = np.mean([r['sync_info']['confidence'] for r in sync_results])
        max_confidence = max([r['sync_info']['confidence'] for r in sync_results])
        
        sync_rate = synced_samples / total_samples if total_samples > 0 else 0
        
        return {
            'total_samples': total_samples,
            'synced_samples': synced_samples,
            'sync_rate': sync_rate,
            'avg_confidence': avg_confidence,
            'max_confidence': max_confidence,
            'sync_threshold': self.sync_threshold
        }

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¼ ì•…ë³´-ì—°ì£¼ ì‹±í¬ ì‹œìŠ¤í…œ ì‹œì‘")
    
    # íŒŒì¼ ê²½ë¡œ
    sheet_music_path = "sheet music_1.png"
    audio_file_path = "ì£¼ í’ˆì— í’ˆìœ¼ì†Œì„œ.mp3"
    
    try:
        # ì‹±í¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        sync_system = SheetMusicSyncSystem(sheet_music_path, audio_file_path)
        
        # ë™ê¸°í™” ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
        sync_results = sync_system.start_sync_monitoring(duration=30.0)
        
        # í†µê³„ ê³„ì‚°
        stats = sync_system.get_sync_statistics(sync_results)
        print(f"\nğŸ“Š ë™ê¸°í™” í†µê³„:")
        print(f"   - ì´ ìƒ˜í”Œ ìˆ˜: {stats['total_samples']}")
        print(f"   - ë™ê¸°í™”ëœ ìƒ˜í”Œ: {stats['synced_samples']}")
        print(f"   - ë™ê¸°í™”ìœ¨: {stats['sync_rate']:.2%}")
        print(f"   - í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']:.3f}")
        print(f"   - ìµœëŒ€ ì‹ ë¢°ë„: {stats['max_confidence']:.3f}")
        
        # ê²°ê³¼ ì‹œê°í™”
        sync_system.visualize_sync_results(sync_results)
        
        # ê²°ê³¼ ì €ì¥
        sync_system.save_sync_results(sync_results)
        
        print("\nâœ… ì•…ë³´-ì—°ì£¼ ì‹±í¬ ì‹œìŠ¤í…œ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
