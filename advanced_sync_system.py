"""
ê³ ê¸‰ ì•…ë³´-ì—°ì£¼ ì‹±í¬ ì‹œìŠ¤í…œ
ê°„ì£¼, ë°˜ë³µ, 1ì ˆ/2ì ˆ ë“±ì„ ê³ ë ¤í•œ ì‹¤ì œ ìŒì•… ì—°ì£¼ êµ¬ì¡° ë¶„ì„
"""

import json
import numpy as np
import time
import matplotlib.pyplot as plt
from typing import List, Dict, Optional, Tuple
from collections import deque
import librosa
from improved_omr import ImprovedOMR
from real_time_audio_processor import RealTimeAudioProcessor

class AdvancedSyncSystem:
    def __init__(self, sheet_music_path: str, audio_file_path: str):
        """
        ê³ ê¸‰ ì•…ë³´-ì—°ì£¼ ì‹±í¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            sheet_music_path: ì•…ë³´ ì´ë¯¸ì§€ ê²½ë¡œ
            audio_file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        self.sheet_music_path = sheet_music_path
        self.audio_file_path = audio_file_path
        
        # OMR ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("ğŸ¼ ê³ ê¸‰ OMR ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        self.omr = ImprovedOMR()
        self.sheet_music_data = None
        
        # ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("ğŸµ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        self.audio_processor = RealTimeAudioProcessor(audio_file_path)
        
        # ìŒì•… êµ¬ì¡° ë¶„ì„
        self.music_structure = {
            'intro_duration': 0.0,  # ê°„ì£¼ ê¸¸ì´
            'verse_duration': 0.0,  # 1ì ˆ ê¸¸ì´
            'total_verses': 0,  # ì´ ì ˆ ìˆ˜
            'repeat_sections': [],  # ë°˜ë³µ êµ¬ê°„ë“¤
            'tempo_changes': [],  # í…œí¬ ë³€í™”
            'structure_timeline': []  # ì „ì²´ êµ¬ì¡° íƒ€ì„ë¼ì¸
        }
        
        # ë™ê¸°í™” ìƒíƒœ
        self.sync_state = {
            'current_section': 'unknown',  # í˜„ì¬ êµ¬ê°„ (intro, verse1, verse2, etc.)
            'current_position': 0,  # í˜„ì¬ ì—°ì£¼ ìœ„ì¹˜ (ìŒí‘œ ì¸ë±ìŠ¤)
            'sync_confidence': 0.0,  # ë™ê¸°í™” ì‹ ë¢°ë„
            'is_synced': False,  # ë™ê¸°í™” ìƒíƒœ
            'tempo': 120.0,  # í˜„ì¬ í…œí¬
            'repeat_count': 0,  # ë°˜ë³µ íšŸìˆ˜
            'sync_history': deque(maxlen=100)
        }
        
        # ë§¤ì¹­ ì„¤ì •
        self.pitch_tolerance = 100  # ìŒë†’ì´ í—ˆìš© ì˜¤ì°¨ (ì„¼íŠ¸) - ë” ê´€ëŒ€í•˜ê²Œ
        self.tempo_tolerance = 0.3  # í…œí¬ í—ˆìš© ì˜¤ì°¨ (30%)
        self.sync_threshold = 0.5  # ë™ê¸°í™” ìµœì†Œ ì‹ ë¢°ë„ - ë‚®ì¶¤
        
        print("âœ… ê³ ê¸‰ ì•…ë³´-ì—°ì£¼ ì‹±í¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def analyze_music_structure(self):
        """ìŒì•… êµ¬ì¡° ë¶„ì„ (ê°„ì£¼, 1ì ˆ/2ì ˆ, ë°˜ë³µ êµ¬ê°„ ë“±)"""
        print("ğŸ” ìŒì•… êµ¬ì¡° ë¶„ì„ ì‹œì‘...")
        
        # ì˜¤ë””ì˜¤ ë¶„ì„
        audio_analysis = self.audio_processor.analyze_full_audio()
        results = audio_analysis['detailed_results']
        
        # 1. ê°„ì£¼ êµ¬ê°„ ì°¾ê¸° (ì²˜ìŒ 30ì´ˆ ë‚´ì—ì„œ ìŒë†’ì´ ë³€í™”ê°€ ì ì€ êµ¬ê°„)
        intro_candidates = self.find_intro_section(results[:300])  # ì²˜ìŒ 30ì´ˆ
        
        # 2. 1ì ˆ/2ì ˆ íŒ¨í„´ ì°¾ê¸° (ìœ ì‚¬í•œ ë©œë¡œë”” íŒ¨í„´)
        verse_patterns = self.find_verse_patterns(results)
        
        # 3. ë°˜ë³µ êµ¬ê°„ ì°¾ê¸°
        repeat_sections = self.find_repeat_sections(results)
        
        # 4. í…œí¬ ë³€í™” ë¶„ì„
        tempo_changes = self.analyze_tempo_changes(results)
        
        # êµ¬ì¡° ì •ë³´ ì €ì¥
        self.music_structure.update({
            'intro_duration': intro_candidates['duration'] if intro_candidates else 0.0,
            'verse_duration': verse_patterns['duration'] if verse_patterns else 0.0,
            'total_verses': verse_patterns['count'] if verse_patterns else 0,
            'repeat_sections': repeat_sections,
            'tempo_changes': tempo_changes
        })
        
        # ì „ì²´ êµ¬ì¡° íƒ€ì„ë¼ì¸ ìƒì„±
        self.create_structure_timeline()
        
        print(f"âœ… ìŒì•… êµ¬ì¡° ë¶„ì„ ì™„ë£Œ:")
        print(f"   - ê°„ì£¼: {self.music_structure['intro_duration']:.1f}ì´ˆ")
        print(f"   - 1ì ˆ ê¸¸ì´: {self.music_structure['verse_duration']:.1f}ì´ˆ")
        print(f"   - ì´ ì ˆ ìˆ˜: {self.music_structure['total_verses']}")
        print(f"   - ë°˜ë³µ êµ¬ê°„: {len(self.music_structure['repeat_sections'])}ê°œ")
    
    def find_intro_section(self, results: List[Dict]) -> Optional[Dict]:
        """ê°„ì£¼ êµ¬ê°„ ì°¾ê¸°"""
        if len(results) < 50:
            return None
        
        # ìŒë†’ì´ ë³€í™”ê°€ ì ê³  ë³¼ë¥¨ì´ ë‚®ì€ êµ¬ê°„ ì°¾ê¸°
        pitch_variance = []
        volume_avg = []
        
        window_size = 20  # 2ì´ˆ ìœˆë„ìš°
        
        for i in range(0, len(results) - window_size, 10):
            window = results[i:i+window_size]
            pitches = [r['pitch'] for r in window if r['pitch'] > 0]
            volumes = [r['volume'] for r in window]
            
            if len(pitches) > 5:
                pitch_var = np.var(pitches)
                vol_avg = np.mean(volumes)
                pitch_variance.append(pitch_var)
                volume_avg.append(vol_avg)
            else:
                pitch_variance.append(float('inf'))
                volume_avg.append(1.0)
        
        # ê°„ì£¼ í›„ë³´: ìŒë†’ì´ ë³€í™”ê°€ ì ê³  ë³¼ë¥¨ì´ ë‚®ì€ êµ¬ê°„
        if pitch_variance:
            min_var_idx = np.argmin(pitch_variance)
            if pitch_variance[min_var_idx] < 1000 and volume_avg[min_var_idx] < 0.1:
                start_time = results[min_var_idx * 10]['time']
                end_time = results[min_var_idx * 10 + window_size]['time']
                return {
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': end_time - start_time,
                    'pitch_variance': pitch_variance[min_var_idx],
                    'volume_avg': volume_avg[min_var_idx]
                }
        
        return None
    
    def find_verse_patterns(self, results: List[Dict]) -> Optional[Dict]:
        """1ì ˆ/2ì ˆ íŒ¨í„´ ì°¾ê¸°"""
        # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­: ìœ ì‚¬í•œ ìŒë†’ì´ ì‹œí€€ìŠ¤ ì°¾ê¸°
        pitch_sequence = [r['pitch'] for r in results if r['pitch'] > 0]
        
        if len(pitch_sequence) < 100:
            return None
        
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ íŒ¨í„´ ì°¾ê¸°
        window_size = 50  # 5ì´ˆ ìœˆë„ìš°
        similarities = []
        
        for i in range(0, len(pitch_sequence) - window_size * 2, 10):
            pattern1 = pitch_sequence[i:i+window_size]
            
            for j in range(i + window_size, len(pitch_sequence) - window_size, 10):
                pattern2 = pitch_sequence[j:j+window_size]
                
                # íŒ¨í„´ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ ìƒê´€ê³„ìˆ˜)
                if len(pattern1) == len(pattern2):
                    similarity = np.corrcoef(pattern1, pattern2)[0, 1]
                    if not np.isnan(similarity):
                        similarities.append({
                            'start1': i,
                            'start2': j,
                            'similarity': similarity,
                            'time1': results[i]['time'],
                            'time2': results[j]['time']
                        })
        
        # ë†’ì€ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ íŒ¨í„´ë“¤ ì°¾ê¸°
        if similarities:
            high_similarities = [s for s in similarities if s['similarity'] > 0.7]
            if high_similarities:
                best_match = max(high_similarities, key=lambda x: x['similarity'])
                verse_duration = best_match['time2'] - best_match['time1']
                
                # ì´ ì ˆ ìˆ˜ ì¶”ì •
                total_duration = results[-1]['time']
                estimated_verses = int(total_duration / verse_duration)
                
                return {
                    'duration': verse_duration,
                    'count': estimated_verses,
                    'similarity': best_match['similarity'],
                    'pattern_match': best_match
                }
        
        return None
    
    def find_repeat_sections(self, results: List[Dict]) -> List[Dict]:
        """ë°˜ë³µ êµ¬ê°„ ì°¾ê¸°"""
        repeat_sections = []
        
        # ê°„ë‹¨í•œ ë°˜ë³µ êµ¬ê°„ ê²€ì¶œ: ë™ì¼í•œ ìŒë†’ì´ íŒ¨í„´ì´ ë°˜ë³µë˜ëŠ” êµ¬ê°„
        pitch_sequence = [r['pitch'] for r in results if r['pitch'] > 0]
        
        if len(pitch_sequence) < 200:
            return repeat_sections
        
        # 10ì´ˆ ë‹¨ìœ„ë¡œ íŒ¨í„´ ê²€ì‚¬
        pattern_size = 100  # 10ì´ˆ íŒ¨í„´
        
        for i in range(0, len(pitch_sequence) - pattern_size * 2, 50):
            pattern = pitch_sequence[i:i+pattern_size]
            
            # ê°™ì€ íŒ¨í„´ì´ ë°˜ë³µë˜ëŠ”ì§€ í™•ì¸
            for j in range(i + pattern_size, len(pitch_sequence) - pattern_size, 50):
                candidate = pitch_sequence[j:j+pattern_size]
                
                if len(pattern) == len(candidate):
                    similarity = np.corrcoef(pattern, candidate)[0, 1]
                    if not np.isnan(similarity) and similarity > 0.8:
                        repeat_sections.append({
                            'start_time': results[i]['time'],
                            'end_time': results[i + pattern_size]['time'],
                            'repeat_start': results[j]['time'],
                            'repeat_end': results[j + pattern_size]['time'],
                            'similarity': similarity
                        })
        
        return repeat_sections
    
    def analyze_tempo_changes(self, results: List[Dict]) -> List[Dict]:
        """í…œí¬ ë³€í™” ë¶„ì„"""
        tempo_changes = []
        
        # ë³¼ë¥¨ê³¼ ìŒë†’ì´ ë³€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…œí¬ ë³€í™” ì¶”ì •
        window_size = 100  # 10ì´ˆ ìœˆë„ìš°
        
        for i in range(0, len(results) - window_size, 50):
            window = results[i:i+window_size]
            
            # ë³¼ë¥¨ ë³€í™”ìœ¨ ê³„ì‚°
            volumes = [r['volume'] for r in window]
            volume_changes = np.diff(volumes)
            volume_variance = np.var(volume_changes)
            
            # ìŒë†’ì´ ë³€í™”ìœ¨ ê³„ì‚°
            pitches = [r['pitch'] for r in window if r['pitch'] > 0]
            if len(pitches) > 10:
                pitch_changes = np.diff(pitches)
                pitch_variance = np.var(pitch_changes)
                
                # í…œí¬ ë³€í™” ì¶”ì • (ë³¼ë¥¨ê³¼ ìŒë†’ì´ ë³€í™” ê¸°ë°˜)
                estimated_tempo = 120 + (volume_variance * 10) + (pitch_variance * 0.1)
                estimated_tempo = max(60, min(180, estimated_tempo))  # 60-180 BPM ë²”ìœ„
                
                tempo_changes.append({
                    'time': results[i]['time'],
                    'tempo': estimated_tempo,
                    'volume_variance': volume_variance,
                    'pitch_variance': pitch_variance
                })
        
        return tempo_changes
    
    def create_structure_timeline(self):
        """ì „ì²´ êµ¬ì¡° íƒ€ì„ë¼ì¸ ìƒì„±"""
        timeline = []
        current_time = 0.0
        
        # ê°„ì£¼
        if self.music_structure['intro_duration'] > 0:
            timeline.append({
                'type': 'intro',
                'start_time': current_time,
                'end_time': current_time + self.music_structure['intro_duration'],
                'description': 'ê°„ì£¼'
            })
            current_time += self.music_structure['intro_duration']
        
        # 1ì ˆ, 2ì ˆ ë“±
        verse_duration = self.music_structure['verse_duration']
        total_verses = self.music_structure['total_verses']
        
        for i in range(total_verses):
            timeline.append({
                'type': f'verse{i+1}',
                'start_time': current_time,
                'end_time': current_time + verse_duration,
                'description': f'{i+1}ì ˆ'
            })
            current_time += verse_duration
        
        # ë°˜ë³µ êµ¬ê°„ë“¤
        for i, repeat in enumerate(self.music_structure['repeat_sections']):
            timeline.append({
                'type': f'repeat{i+1}',
                'start_time': repeat['start_time'],
                'end_time': repeat['end_time'],
                'description': f'ë°˜ë³µ êµ¬ê°„ {i+1}'
            })
        
        self.music_structure['structure_timeline'] = timeline
    
    def load_sheet_music(self):
        """ì•…ë³´ ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“„ ì•…ë³´ ë°ì´í„° ë¡œë”©...")
        
        # OMRë¡œ ì•…ë³´ ë¶„ì„
        self.sheet_music_data = self.omr.process_sheet_music_improved(self.sheet_music_path)
        
        # ìŒí‘œ ë°ì´í„°ë¥¼ ì‹œê°„ì¶•ìœ¼ë¡œ ë³€í™˜
        self.convert_notes_to_timeline()
        
        print(f"âœ… ì•…ë³´ ë¡œë“œ ì™„ë£Œ: {len(self.sheet_music_data['notes'])}ê°œ ìŒí‘œ")
    
    def convert_notes_to_timeline(self):
        """ìŒí‘œ ë°ì´í„°ë¥¼ ì‹œê°„ì¶•ìœ¼ë¡œ ë³€í™˜ (ë°˜ë³µ êµ¬ì¡° ê³ ë ¤)"""
        if not self.sheet_music_data or 'notes' not in self.sheet_music_data:
            return
        
        notes = self.sheet_music_data['notes']
        tempo = self.sync_state['tempo']
        
        # ê¸°ë³¸ 1ì ˆ ê¸¸ì´ ê³„ì‚°
        base_duration = 0.0
        for note in notes:
            note_duration = note.get('duration', 1.0)
            base_duration += (note_duration * 60.0 / tempo)
        
        # ìŒì•… êµ¬ì¡°ì— ë§ê²Œ ì‹œê°„ì¶• ì¡°ì •
        current_time = 0.0
        
        # ê°„ì£¼ ì‹œê°„ ì¶”ê°€
        if self.music_structure['intro_duration'] > 0:
            current_time += self.music_structure['intro_duration']
        
        # ê° ìŒí‘œì— ì‹œê°„ ì •ë³´ ì¶”ê°€
        for i, note in enumerate(notes):
            note['start_time'] = current_time
            
            note_duration = note.get('duration', 1.0)
            note['end_time'] = current_time + (note_duration * 60.0 / tempo)
            
            current_time = note['end_time']
            note['index'] = i
        
        print(f"âœ… ì‹œê°„ì¶• ë³€í™˜ ì™„ë£Œ: ì´ {current_time:.2f}ì´ˆ")
    
    def find_best_match_with_structure(self, current_pitch: float, current_time: float) -> Tuple[Optional[Dict], float]:
        """ìŒì•… êµ¬ì¡°ë¥¼ ê³ ë ¤í•œ ìµœì  ë§¤ì¹­"""
        if not self.sheet_music_data or 'notes' not in self.sheet_music_data:
            return None, 0.0
        
        notes = self.sheet_music_data['notes']
        best_match = None
        best_score = 0.0
        
        # í˜„ì¬ ì‹œê°„ì´ ì–´ëŠ êµ¬ê°„ì— ì†í•˜ëŠ”ì§€ í™•ì¸
        current_section = self.get_current_section(current_time)
        
        # í•´ë‹¹ êµ¬ê°„ì— ë§ëŠ” ìŒí‘œë“¤ ê²€ì‚¬
        for note in notes:
            note_freq = self.note_name_to_frequency(note['pitch'])
            
            # ì‹œê°„ ë§¤ì¹­ (êµ¬ê°„ë³„ë¡œ ë‹¤ë¥¸ ìœˆë„ìš° ì ìš©)
            time_window = self.get_time_window_for_section(current_section)
            time_diff = abs(current_time - note['start_time'])
            
            if time_diff > time_window:
                continue
            
            time_score = 1.0 - (time_diff / time_window)
            
            # ìŒë†’ì´ ë§¤ì¹­
            pitch_score = self.match_pitch(current_pitch, note_freq)
            
            # êµ¬ê°„ë³„ ê°€ì¤‘ì¹˜ ì ìš©
            section_weight = self.get_section_weight(current_section)
            
            # ì¢…í•© ì ìˆ˜
            total_score = (0.4 * time_score + 0.6 * pitch_score) * section_weight
            
            if total_score > best_score:
                best_score = total_score
                best_match = note
        
        return best_match, best_score
    
    def get_current_section(self, current_time: float) -> str:
        """í˜„ì¬ ì‹œê°„ì´ ì†í•˜ëŠ” êµ¬ê°„ ë°˜í™˜"""
        for section in self.music_structure['structure_timeline']:
            if section['start_time'] <= current_time <= section['end_time']:
                return section['type']
        return 'unknown'
    
    def get_time_window_for_section(self, section: str) -> float:
        """êµ¬ê°„ë³„ ì‹œê°„ ìœˆë„ìš° ë°˜í™˜"""
        windows = {
            'intro': 10.0,  # ê°„ì£¼ëŠ” ë” ë„“ì€ ìœˆë„ìš°
            'verse1': 5.0,
            'verse2': 5.0,
            'repeat1': 8.0,  # ë°˜ë³µ êµ¬ê°„ì€ ì¤‘ê°„ ìœˆë„ìš°
            'unknown': 15.0  # ì•Œ ìˆ˜ ì—†ëŠ” êµ¬ê°„ì€ ë„“ì€ ìœˆë„ìš°
        }
        return windows.get(section, 5.0)
    
    def get_section_weight(self, section: str) -> float:
        """êµ¬ê°„ë³„ ê°€ì¤‘ì¹˜ ë°˜í™˜"""
        weights = {
            'intro': 0.8,  # ê°„ì£¼ëŠ” ë‚®ì€ ê°€ì¤‘ì¹˜
            'verse1': 1.0,  # 1ì ˆì€ ë†’ì€ ê°€ì¤‘ì¹˜
            'verse2': 1.0,  # 2ì ˆë„ ë†’ì€ ê°€ì¤‘ì¹˜
            'repeat1': 0.9,  # ë°˜ë³µ êµ¬ê°„ì€ ì¤‘ê°„ ê°€ì¤‘ì¹˜
            'unknown': 0.5  # ì•Œ ìˆ˜ ì—†ëŠ” êµ¬ê°„ì€ ë‚®ì€ ê°€ì¤‘ì¹˜
        }
        return weights.get(section, 1.0)
    
    def match_pitch(self, current_pitch: float, note_frequency: float) -> float:
        """ìŒë†’ì´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        if current_pitch <= 0 or note_frequency <= 0:
            return 0.0
        
        cents_diff = abs(self.frequency_to_cents(current_pitch, note_frequency))
        
        if cents_diff <= self.pitch_tolerance:
            return 1.0 - (cents_diff / self.pitch_tolerance)
        else:
            return 0.0
    
    def frequency_to_cents(self, freq1: float, freq2: float) -> float:
        """ë‘ ì£¼íŒŒìˆ˜ ê°„ì˜ ì„¼íŠ¸ ì°¨ì´ ê³„ì‚°"""
        if freq1 <= 0 or freq2 <= 0:
            return float('inf')
        return 1200 * np.log2(freq2 / freq1)
    
    def note_name_to_frequency(self, note_name: str) -> float:
        """ìŒí‘œëª…ì„ ì£¼íŒŒìˆ˜ë¡œ ë³€í™˜"""
        if note_name == "Silence":
            return 0.0
        
        note_map = {
            'C': -9, 'C#': -8, 'D': -7, 'D#': -6, 'E': -5, 'F': -4,
            'F#': -3, 'G': -2, 'G#': -1, 'A': 0, 'A#': 1, 'B': 2
        }
        
        try:
            note = note_name[:-1]
            octave = int(note_name[-1])
            semitones = note_map[note] + (octave - 4) * 12
            frequency = 440.0 * (2 ** (semitones / 12))
            return frequency
        except:
            return 0.0
    
    def start_advanced_sync_monitoring(self, duration: float = 60.0):
        """ê³ ê¸‰ ë™ê¸°í™” ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        print(f"ğŸ”„ ê³ ê¸‰ ë™ê¸°í™” ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ìµœëŒ€ {duration}ì´ˆ)...")
        
        # ìŒì•… êµ¬ì¡° ë¶„ì„
        self.analyze_music_structure()
        
        # ì•…ë³´ ë°ì´í„° ë¡œë“œ
        self.load_sheet_music()
        
        # ì˜¤ë””ì˜¤ ë¶„ì„
        print("ğŸ” ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘...")
        audio_analysis = self.audio_processor.analyze_full_audio()
        
        # ì‹¤ì‹œê°„ ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜
        results = audio_analysis['detailed_results']
        sync_results = []
        
        for result in results[:int(duration * 10)]:  # 0.1ì´ˆ ë‹¨ìœ„ë¡œ ì œí•œ
            current_time = result['time']
            current_pitch = result['pitch']
            
            # ê³ ê¸‰ ë§¤ì¹­ ìˆ˜í–‰
            best_match, match_score = self.find_best_match_with_structure(current_pitch, current_time)
            
            # ë™ê¸°í™” ìƒíƒœ ì—…ë°ì´íŠ¸
            if best_match and match_score >= self.sync_threshold:
                self.sync_state['current_position'] = best_match['index']
                self.sync_state['sync_confidence'] = match_score
                self.sync_state['is_synced'] = True
                self.sync_state['current_section'] = self.get_current_section(current_time)
            else:
                self.sync_state['sync_confidence'] = match_score
                self.sync_state['is_synced'] = False
            
            # ê²°ê³¼ ì €ì¥
            sync_results.append({
                'time': current_time,
                'audio_pitch': current_pitch,
                'matched_note': best_match,
                'match_score': match_score,
                'current_section': self.sync_state['current_section'],
                'sync_state': self.sync_state.copy()
            })
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if len(sync_results) % 100 == 0:  # 10ì´ˆë§ˆë‹¤ ì¶œë ¥
                section = self.sync_state['current_section']
                print(f"â±ï¸ {current_time:.1f}ì´ˆ [{section}]: "
                      f"ìŒë†’ì´={current_pitch:.1f}Hz, "
                      f"ë§¤ì¹­ì ìˆ˜={match_score:.3f}, "
                      f"ë™ê¸°í™”={'âœ…' if self.sync_state['is_synced'] else 'âŒ'}")
        
        return sync_results
    
    def visualize_advanced_sync_results(self, sync_results: List[Dict]):
        """ê³ ê¸‰ ë™ê¸°í™” ê²°ê³¼ ì‹œê°í™”"""
        print("ğŸ“Š ê³ ê¸‰ ë™ê¸°í™” ê²°ê³¼ ì‹œê°í™”...")
        
        times = [r['time'] for r in sync_results]
        audio_pitches = [r['audio_pitch'] for r in sync_results]
        match_scores = [r['match_score'] for r in sync_results]
        sections = [r['current_section'] for r in sync_results]
        
        # ê·¸ë˜í”„ ìƒì„±
        fig, axes = plt.subplots(4, 1, figsize=(15, 16))
        
        # 1. ì˜¤ë””ì˜¤ ìŒë†’ì´
        axes[0].plot(times, audio_pitches, 'b-', alpha=0.7, label='Audio Pitch')
        axes[0].set_title('Audio Pitch Over Time')
        axes[0].set_ylabel('Frequency (Hz)')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # 2. ë§¤ì¹­ ì ìˆ˜
        axes[1].plot(times, match_scores, 'g-', alpha=0.7)
        axes[1].axhline(y=self.sync_threshold, color='orange', linestyle='--', label='Sync Threshold')
        axes[1].set_title('Matching Score')
        axes[1].set_ylabel('Score')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        # 3. ìŒì•… êµ¬ê°„
        section_colors = {'intro': 'red', 'verse1': 'blue', 'verse2': 'green', 'repeat1': 'orange', 'unknown': 'gray'}
        for i, section in enumerate(sections):
            if section in section_colors:
                axes[2].scatter(times[i], 1, c=section_colors[section], s=10, alpha=0.7)
        axes[2].set_title('Music Sections')
        axes[2].set_ylabel('Section')
        axes[2].set_ylim(0.5, 1.5)
        axes[2].grid(True, alpha=0.3)
        
        # 4. ë™ê¸°í™” ìƒíƒœ
        sync_status = [1 if r['sync_state']['is_synced'] else 0 for r in sync_results]
        axes[3].plot(times, sync_status, 'r-', alpha=0.7)
        axes[3].set_title('Sync Status')
        axes[3].set_ylabel('Synced (1/0)')
        axes[3].set_xlabel('Time (seconds)')
        axes[3].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('advanced_sync_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("âœ… ê³ ê¸‰ ì‹œê°í™” ì™„ë£Œ: advanced_sync_analysis.png")
    
    def save_advanced_sync_results(self, sync_results: List[Dict], filename: str = 'advanced_sync_results.json'):
        """ê³ ê¸‰ ë™ê¸°í™” ê²°ê³¼ ì €ì¥"""
        def convert_numpy_types(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, deque):
                return list(obj)
            elif isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            return obj
        
        # ê²°ê³¼ì™€ ìŒì•… êµ¬ì¡° ì •ë³´ ëª¨ë‘ ì €ì¥
        save_data = {
            'sync_results': sync_results,
            'music_structure': self.music_structure,
            'sync_statistics': self.get_advanced_sync_statistics(sync_results)
        }
        
        serializable_data = convert_numpy_types(save_data)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(serializable_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ê³ ê¸‰ ë™ê¸°í™” ê²°ê³¼ ì €ì¥: {filename}")
    
    def get_advanced_sync_statistics(self, sync_results: List[Dict]) -> Dict:
        """ê³ ê¸‰ ë™ê¸°í™” í†µê³„ ê³„ì‚°"""
        total_samples = len(sync_results)
        synced_samples = sum(1 for r in sync_results if r['sync_state']['is_synced'])
        
        avg_score = np.mean([r['match_score'] for r in sync_results])
        max_score = max([r['match_score'] for r in sync_results])
        
        # êµ¬ê°„ë³„ í†µê³„
        section_stats = {}
        for section in set(r['current_section'] for r in sync_results):
            section_results = [r for r in sync_results if r['current_section'] == section]
            section_synced = sum(1 for r in section_results if r['sync_state']['is_synced'])
            section_stats[section] = {
                'total_samples': len(section_results),
                'synced_samples': section_synced,
                'sync_rate': section_synced / len(section_results) if section_results else 0,
                'avg_score': np.mean([r['match_score'] for r in section_results])
            }
        
        return {
            'total_samples': total_samples,
            'synced_samples': synced_samples,
            'overall_sync_rate': synced_samples / total_samples if total_samples > 0 else 0,
            'avg_match_score': avg_score,
            'max_match_score': max_score,
            'section_statistics': section_stats,
            'music_structure_summary': {
                'intro_duration': self.music_structure['intro_duration'],
                'verse_duration': self.music_structure['verse_duration'],
                'total_verses': self.music_structure['total_verses'],
                'repeat_sections_count': len(self.music_structure['repeat_sections'])
            }
        }

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¼ ê³ ê¸‰ ì•…ë³´-ì—°ì£¼ ì‹±í¬ ì‹œìŠ¤í…œ ì‹œì‘")
    
    # íŒŒì¼ ê²½ë¡œ
    sheet_music_path = "sheet music_1.png"
    audio_file_path = "ì£¼ í’ˆì— í’ˆìœ¼ì†Œì„œ.mp3"
    
    try:
        # ê³ ê¸‰ ì‹±í¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        sync_system = AdvancedSyncSystem(sheet_music_path, audio_file_path)
        
        # ê³ ê¸‰ ë™ê¸°í™” ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
        sync_results = sync_system.start_advanced_sync_monitoring(duration=60.0)
        
        # í†µê³„ ê³„ì‚° ë° ì¶œë ¥
        stats = sync_system.get_advanced_sync_statistics(sync_results)
        print(f"\nğŸ“Š ê³ ê¸‰ ë™ê¸°í™” í†µê³„:")
        print(f"   - ì´ ìƒ˜í”Œ ìˆ˜: {stats['total_samples']}")
        print(f"   - ë™ê¸°í™”ëœ ìƒ˜í”Œ: {stats['synced_samples']}")
        print(f"   - ì „ì²´ ë™ê¸°í™”ìœ¨: {stats['overall_sync_rate']:.2%}")
        print(f"   - í‰ê·  ë§¤ì¹­ ì ìˆ˜: {stats['avg_match_score']:.3f}")
        print(f"   - ìµœëŒ€ ë§¤ì¹­ ì ìˆ˜: {stats['max_match_score']:.3f}")
        
        print(f"\nğŸµ ìŒì•… êµ¬ì¡° ìš”ì•½:")
        print(f"   - ê°„ì£¼: {stats['music_structure_summary']['intro_duration']:.1f}ì´ˆ")
        print(f"   - 1ì ˆ ê¸¸ì´: {stats['music_structure_summary']['verse_duration']:.1f}ì´ˆ")
        print(f"   - ì´ ì ˆ ìˆ˜: {stats['music_structure_summary']['total_verses']}")
        print(f"   - ë°˜ë³µ êµ¬ê°„: {stats['music_structure_summary']['repeat_sections_count']}ê°œ")
        
        print(f"\nğŸ“ˆ êµ¬ê°„ë³„ ë™ê¸°í™”ìœ¨:")
        for section, section_stats in stats['section_statistics'].items():
            print(f"   - {section}: {section_stats['sync_rate']:.2%} ({section_stats['synced_samples']}/{section_stats['total_samples']})")
        
        # ê²°ê³¼ ì‹œê°í™”
        sync_system.visualize_advanced_sync_results(sync_results)
        
        # ê²°ê³¼ ì €ì¥
        sync_system.save_advanced_sync_results(sync_results)
        
        print("\nâœ… ê³ ê¸‰ ì•…ë³´-ì—°ì£¼ ì‹±í¬ ì‹œìŠ¤í…œ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
